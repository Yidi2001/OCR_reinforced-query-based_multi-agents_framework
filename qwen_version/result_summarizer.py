#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»“æœæ‘˜è¦å™¨ï¼šä»Pipelineè¾“å‡ºçš„JSONä¸­æå–å…³é”®ä¿¡æ¯
ç”¨äºç”Ÿæˆç»™å¤§æ¨¡å‹çš„ç®€æ´æç¤ºä¿¡æ¯
"""

import json
from pathlib import Path
from typing import Dict, Any, List
from collections import Counter


class ResultSummarizer:
    """æå–Pipelineæ‰§è¡Œç»“æœçš„å…³é”®ä¿¡æ¯"""
    
    def __init__(self, max_ocr_text_length: int = 500):
        """
        Args:
            max_ocr_text_length: OCRæ–‡æœ¬æ‘˜è¦çš„æœ€å¤§é•¿åº¦
        """
        self.max_ocr_text_length = max_ocr_text_length
    
    def summarize_from_file(self, json_path: str) -> Dict[str, Any]:
        """ä»JSONæ–‡ä»¶ä¸­æå–å…³é”®ä¿¡æ¯æ‘˜è¦"""
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return self.summarize(data)
    
    def summarize(self, result_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        æå–å…³é”®ä¿¡æ¯æ‘˜è¦
        
        é‡ç‚¹æå–ï¼š
        1. åŸºæœ¬ä¿¡æ¯ï¼šå›¾ç‰‡è·¯å¾„ã€åˆ†è¾¨ç‡ã€åˆ†ç±»ç»“æœ
        2. OCRç»“æœï¼šå¦‚æœæœ‰å¸ƒå±€æ£€æµ‹ï¼Œæå–æ¯ä¸ªåŒºåŸŸçš„è¯†åˆ«ç»“æœï¼›å¦åˆ™æå–æ•´ä½“è¯†åˆ«ç»“æœ
        
        Args:
            result_data: Pipelineè¾“å‡ºçš„å®Œæ•´JSONæ•°æ®
            
        Returns:
            å…³é”®ä¿¡æ¯å­—å…¸
        """
        exec_results = result_data.get('execution_results', {})
        layout_result = exec_results.get('layout_result')
        
        summary = {
            # åŸºæœ¬ä¿¡æ¯
            "image_path": result_data.get('image_path', ''),
            "resolution": self._get_resolution(result_data),
            "user_query": result_data.get('query', ''),
            "classification": self._extract_classification(result_data),
            
            # OCRè¯†åˆ«ç»“æœ
            "ocr_results": self._extract_ocr_results(result_data, layout_result),
            
            # æ‰§è¡Œä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
            "agent_sequence": self._get_agent_sequence(result_data),
            "total_time": result_data.get('total_time', 0)
        }
        
        return summary
    
    def format_as_prompt(self, summary: Dict[str, Any]) -> str:
        """
        å°†æ‘˜è¦æ ¼å¼åŒ–ä¸ºé€‚åˆå¤§æ¨¡å‹çš„æç¤ºä¿¡æ¯
        
        Args:
            summary: å…³é”®ä¿¡æ¯å­—å…¸
            
        Returns:
            æ ¼å¼åŒ–çš„æç¤ºæ–‡æœ¬
        """
        prompt_parts = []
        
        # åŸºæœ¬ä¿¡æ¯
        prompt_parts.append("=" * 80)
        prompt_parts.append("å›¾åƒOCRè¯†åˆ«ç»“æœæ‘˜è¦")
        prompt_parts.append("=" * 80)
        prompt_parts.append("")
        
        # å›¾åƒè·¯å¾„å’Œåˆ†è¾¨ç‡
        prompt_parts.append(f"ğŸ“· å›¾åƒè·¯å¾„: {summary['image_path']}")
        prompt_parts.append(f"ğŸ“ åˆ†è¾¨ç‡: {summary['resolution']}")
        prompt_parts.append("")
        
        # ç”¨æˆ·æŸ¥è¯¢
        if summary.get('user_query'):
            prompt_parts.append(f"â“ ç”¨æˆ·æŸ¥è¯¢: {summary['user_query']}")
            prompt_parts.append("")
        
        # æ–‡æœ¬ç±»å‹åˆ†ç±»
        cls = summary['classification']
        prompt_parts.append(f"ğŸ” æ–‡æœ¬ç±»å‹: {cls['label']} (ç½®ä¿¡åº¦: {cls['confidence']:.1%})")
        prompt_parts.append("")
        
        # Agentæ‰§è¡Œåºåˆ—
        if summary.get('agent_sequence'):
            prompt_parts.append(f"âš™ï¸  æ‰§è¡Œåºåˆ—: {' â†’ '.join(summary['agent_sequence'])}")
            prompt_parts.append("")
        
        # OCRè¯†åˆ«ç»“æœ
        ocr_results = summary['ocr_results']
        prompt_parts.append("=" * 80)
        prompt_parts.append("ğŸ“ OCRè¯†åˆ«ç»“æœ")
        prompt_parts.append("=" * 80)
        prompt_parts.append("")
        
        if ocr_results['type'] == 'layout_based':
            # åŸºäºå¸ƒå±€æ£€æµ‹çš„ç»“æœ
            is_merged = ocr_results.get('merged', False)
            if is_merged:
                merge_stats = ocr_results.get('merge_stats', {})
                original_count = merge_stats.get('original_regions', 0)
                prompt_parts.append(f"âœ“ ä½¿ç”¨å¸ƒå±€æ£€æµ‹å’Œæ™ºèƒ½æ•´åˆ")
                prompt_parts.append(f"  åŸå§‹åŒºåŸŸ: {original_count} â†’ æ•´åˆå: {ocr_results['total_regions']} ä¸ªåŒºåŸŸ")
            else:
                prompt_parts.append(f"âœ“ ä½¿ç”¨å¸ƒå±€æ£€æµ‹ï¼Œå…±è¯†åˆ« {ocr_results['total_regions']} ä¸ªåŒºåŸŸ")
            prompt_parts.append("")
            
            for region in ocr_results['regions']:
                prompt_parts.append(f"ã€åŒºåŸŸ {region['region_id']}ã€‘")
                prompt_parts.append(f"  ç±»å‹: {region['label']}")
                prompt_parts.append(f"  ç½®ä¿¡åº¦: {region['confidence']}")
                prompt_parts.append(f"  åæ ‡: {region['coordinate']}")
                
                # å¦‚æœæœ‰æ ‡é¢˜ï¼Œæ˜¾ç¤ºæ ‡é¢˜
                if region.get('title'):
                    prompt_parts.append(f"  æ ‡é¢˜: {region['title']}")
                
                # å¦‚æœæœ‰å­åŒºåŸŸæ•°é‡ï¼Œæ˜¾ç¤º
                if region.get('children_count'):
                    prompt_parts.append(f"  åŒ…å«å­åŒºåŸŸ: {region['children_count']}")
                
                prompt_parts.append(f"  è¯†åˆ«æ–‡å­—:")
                if region['text']:
                    # åœ¨æç¤ºæ–‡æœ¬ä¸­ï¼Œå¦‚æœæ–‡å­—å¤ªé•¿ï¼Œå¯ä»¥é€‚å½“æˆªæ–­ä»¥ä¾¿é˜…è¯»
                    # ä½†ä¿ç•™å‰500ä¸ªå­—ç¬¦ï¼Œè¶³å¤ŸæŸ¥çœ‹ä¸»è¦å†…å®¹
                    text_for_display = region['text']
                    if len(text_for_display) > 500:
                        text_for_display = text_for_display[:500] + "\n    ... (å®Œæ•´å†…å®¹è§summary.json)"
                    # æ·»åŠ ç¼©è¿›
                    indented_text = '\n    '.join(text_for_display.split('\n'))
                    prompt_parts.append(f"    {indented_text}")
                else:
                    prompt_parts.append(f"    (æœªè¯†åˆ«åˆ°æ–‡å­—)")
                prompt_parts.append("")
            
            if ocr_results.get('visualized_image'):
                prompt_parts.append(f"ğŸ–¼ï¸  å¯è§†åŒ–å›¾ç‰‡: {ocr_results['visualized_image']}")
                prompt_parts.append("")
        
        else:
            # æ•´å›¾è¯†åˆ«ç»“æœ
            prompt_parts.append("âœ“ æ•´å›¾è¯†åˆ«")
            prompt_parts.append("")
            prompt_parts.append("è¯†åˆ«æ–‡å­—:")
            prompt_parts.append(ocr_results['text'])
            prompt_parts.append("")
        
        # æ€§èƒ½ä¿¡æ¯
        if summary.get('total_time'):
            prompt_parts.append("=" * 80)
            prompt_parts.append(f"â±ï¸  æ€»è€—æ—¶: {summary['total_time']:.2f}ç§’")
        
        return "\n".join(prompt_parts)
    
    def _get_resolution(self, data: Dict) -> str:
        """è·å–å›¾ç‰‡åˆ†è¾¨ç‡"""
        quality = data.get('task_plan', {}).get('quality_analysis', {})
        return quality.get('resolution', 'unknown')
    
    def _get_agent_sequence(self, data: Dict) -> list:
        """è·å–Agentæ‰§è¡Œåºåˆ—"""
        exec_results = data.get('execution_results', {})
        agents_executed = exec_results.get('agents_executed', [])
        return [a.get('agent_name', '') for a in agents_executed]
    
    def _extract_classification(self, data: Dict) -> Dict:
        """æå–æ–‡æœ¬ç±»å‹åˆ†ç±»ä¿¡æ¯"""
        cls = data.get('classification', {})
        return {
            "label": cls.get('label', 'unknown'),
            "confidence": cls.get('confidence', 0.0),
            "probabilities": cls.get('probabilities', {})
        }
    
    def _extract_ocr_results(self, data: Dict, layout_result: Dict) -> Dict:
        """
        æå–OCRè¯†åˆ«ç»“æœ
        
        å¦‚æœæœ‰å¸ƒå±€æ£€æµ‹ï¼Œæå–æ¯ä¸ªåŒºåŸŸçš„è¯¦ç»†ä¿¡æ¯ï¼›
        å¦åˆ™æå–æ•´ä½“è¯†åˆ«ç»“æœã€‚
        """
        exec_results = data.get('execution_results', {})
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†å¸ƒå±€æ£€æµ‹
        if layout_result and layout_result.get('detected_regions', 0) > 0:
            return self._extract_layout_based_ocr(layout_result, exec_results)
        else:
            return self._extract_whole_image_ocr(exec_results)
    
    def _extract_layout_based_ocr(self, layout_result: Dict, exec_results: Dict) -> Dict:
        """æå–åŸºäºå¸ƒå±€æ£€æµ‹çš„OCRç»“æœ - å®Œæ•´ä¿ç•™åŸå§‹è¯†åˆ«å†…å®¹"""
        
        # ä¼˜å…ˆä½¿ç”¨æ•´åˆåçš„ merged_blocksï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        merged_blocks = layout_result.get('merged_blocks', [])
        if merged_blocks:
            return self._extract_from_merged_blocks(merged_blocks, layout_result)
        
        # å¦åˆ™ä½¿ç”¨åŸå§‹çš„ boxes
        boxes = layout_result.get('boxes', [])
        
        # ä»agents_executedä¸­è·å–OCR agentçš„è¾“å‡º
        agents_executed = exec_results.get('agents_executed', [])
        ocr_agent_output = None
        
        for agent in agents_executed:
            if 'OCRAgent' in agent.get('agent_name', ''):
                ocr_agent_output = agent.get('output', '')
                break
        
        # è§£æOCRè¾“å‡ºï¼Œå®Œæ•´æå–æ¯ä¸ªåŒºåŸŸçš„è¯†åˆ«ç»“æœ
        regions = []
        
        if ocr_agent_output and isinstance(ocr_agent_output, str):
            # OCRè¾“å‡ºæ ¼å¼ï¼šåŒºåŸŸ X: label (ç½®ä¿¡åº¦: Y)\nä½ç½®: [coords]\næ–‡å­—å†…å®¹:\n...
            # æŒ‰åˆ†éš”ç¬¦åˆ†å‰²
            region_blocks = ocr_agent_output.split('------------------------------------------------------------')
            
            # ç¬¬ä¸€ä¸ªå—åŒ…å«æ ‡é¢˜å’ŒåŒºåŸŸ1ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
            # å…¶ä½™å—ä¾æ¬¡å¯¹åº”åŒºåŸŸ2, 3, 4...
            
            for i, box in enumerate(boxes):
                block = None
                
                if i == 0 and region_blocks:
                    # åŒºåŸŸ1åœ¨ç¬¬ä¸€ä¸ªå—ä¸­
                    block = region_blocks[0]
                elif i < len(region_blocks):
                    # å…¶ä»–åŒºåŸŸåœ¨å¯¹åº”çš„å—ä¸­ï¼ˆæ³¨æ„ç´¢å¼•åç§»ï¼‰
                    block = region_blocks[i]
                
                if not block:
                    continue
                
                # å®Œæ•´æå–æ–‡å­—å†…å®¹ï¼ˆä¸åšä»»ä½•åˆ å‡ï¼‰
                text_content = self._extract_full_text_from_block(block)
                
                region_info = {
                    "region_id": i + 1,
                    "label": box.get('label', 'unknown'),
                    "confidence": round(box.get('score', 0), 3),
                    "coordinate": box.get('coordinate', []),
                    "text": text_content
                }
                regions.append(region_info)
        
        return {
            "type": "layout_based",
            "total_regions": layout_result.get('detected_regions', 0),
            "regions": regions,
            "visualized_image": layout_result.get('visualized_image_path', '')
        }
    
    def _extract_whole_image_ocr(self, exec_results: Dict) -> Dict:
        """æå–æ•´å›¾OCRç»“æœï¼ˆæ— å¸ƒå±€æ£€æµ‹ï¼‰"""
        final_output = exec_results.get('final_output', '')
        
        return {
            "type": "whole_image",
            "text": final_output[:self.max_ocr_text_length] if len(final_output) > self.max_ocr_text_length else final_output
        }
    
    def _extract_full_text_from_block(self, block: str) -> str:
        """
        ä»OCRè¾“å‡ºå—ä¸­å®Œæ•´æå–æ–‡å­—å†…å®¹
        ä¿ç•™åŸå§‹è¯†åˆ«ç»“æœçš„æ‰€æœ‰å†…å®¹ï¼Œä¸åšä»»ä½•åˆ å‡
        """
        if not block:
            return ""
        
        # æŸ¥æ‰¾"æ–‡å­—å†…å®¹:"æ ‡è®°
        marker = "æ–‡å­—å†…å®¹:"
        if marker not in block:
            marker = "æ–‡å­—å†…å®¹ï¼š"
        
        if marker not in block:
            # å¦‚æœæ²¡æœ‰"æ–‡å­—å†…å®¹:"æ ‡è®°ï¼Œè¿”å›ç©º
            return ""
        
        # æå–"æ–‡å­—å†…å®¹:"ä¹‹åçš„æ‰€æœ‰å†…å®¹
        parts = block.split(marker, 1)
        if len(parts) < 2:
            return ""
        
        # è·å–æ–‡å­—å†…å®¹éƒ¨åˆ†ï¼Œå»é™¤é¦–å°¾ç©ºç™½
        text_content = parts[1].strip()
        
        return text_content
    
    def _extract_from_merged_blocks(self, merged_blocks: list, layout_result: Dict) -> Dict:
        """
        ä»æ•´åˆåçš„ merged_blocks ä¸­æå–ä¿¡æ¯
        
        merged_blocks æ ¼å¼:
        [
          {
            "block_id": 1,
            "bbox": [x1, y1, x2, y2],
            "title": "æ ‡é¢˜æ–‡å­—",
            "labels": ["text", "paragraph_title"],
            "text": "æ•´åˆåçš„å®Œæ•´æ–‡å­—",
            "children": [...]
          }
        ]
        
        Args:
            merged_blocks: æ•´åˆåçš„å—åˆ—è¡¨
            layout_result: åŸå§‹å¸ƒå±€ç»“æœï¼ˆç”¨äºè·å–å¯è§†åŒ–å›¾ç‰‡è·¯å¾„ï¼‰
            
        Returns:
            OCRç»“æœå­—å…¸
        """
        regions = []
        
        for block in merged_blocks:
            block_id = block.get('block_id')
            bbox = block.get('bbox', [])
            title = block.get('title', '')
            labels = block.get('labels', [])
            text = block.get('text', '')
            children_count = len(block.get('children', []))
            
            # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦ï¼ˆä»childrenä¸­ï¼‰
            children = block.get('children', [])
            if children:
                avg_confidence = sum(c.get('confidence', 0) for c in children) / len(children)
            else:
                avg_confidence = 0.0
            
            # æ„å»ºåŒºåŸŸä¿¡æ¯
            region_info = {
                "region_id": block_id,
                "label": ", ".join(labels) if labels else "merged_block",
                "confidence": round(avg_confidence, 3),
                "coordinate": bbox,
                "text": text,
                "title": title,
                "children_count": children_count
            }
            
            regions.append(region_info)
        
        return {
            "type": "layout_based",
            "total_regions": len(merged_blocks),
            "regions": regions,
            "visualized_image": layout_result.get('visualized_image_path', ''),
            "merged": True,  # æ ‡è®°è¿™æ˜¯æ•´åˆåçš„ç»“æœ
            "merge_stats": layout_result.get('merge_stats', {})
        }
    
    def _extract_text_from_block(self, block: str) -> str:
        """
        ä»OCRè¾“å‡ºå—ä¸­æå–çº¯æ–‡å­—å†…å®¹
        åªæå–å®é™…è¯†åˆ«çš„æ–‡å­—ï¼Œè·³è¿‡æ‰€æœ‰è§£é‡Šæ€§å†…å®¹
        """
        if not block:
            return ""
        
        lines = block.split('\n')
        text_lines = []
        in_text_section = False
        stop_extraction = False
        
        for line in lines:
            line_stripped = line.strip()
            
            # è¯†åˆ«æ–‡å­—å†…å®¹å¼€å§‹æ ‡è®°
            if 'æ–‡å­—å†…å®¹' in line_stripped:
                in_text_section = True
                continue
            
            # é‡åˆ°è¿™äº›æ ‡é¢˜å°±åœæ­¢æå–ï¼ˆéƒ½æ˜¯è§£é‡Šæ€§å†…å®¹ï¼‰
            if any(stop_word in line_stripped for stop_word in [
                '**ä¸­æ–‡ç¿»è¯‘', 'ä¸­æ–‡ç¿»è¯‘ï¼š', '**ç¿»è¯‘',
                '**è¯†åˆ«è¦ç‚¹', 'è¯†åˆ«è¦ç‚¹ï¼š', 
                '**è¯†åˆ«ç»“æœæ˜¾ç¤º', 'è¯†åˆ«ç»“æœæ˜¾ç¤ºï¼š',
                '**è¯†åˆ«è¯´æ˜', 'è¯†åˆ«è¯´æ˜ï¼š',
                '**è¯´æ˜ï¼š', 'è¯´æ˜ï¼š',
                'è¿™æ˜¯ä¸€ä¸ª', 'è¿™çœ‹èµ·æ¥', 'ä»è¯†åˆ«ç»“æœ', 'ä»å†…å®¹å¯ä»¥çœ‹å‡º',
                'æ‚¨å¯ä»¥', 'éœ€è¦æ³¨æ„', 'å¦‚æœæ‚¨'
            ]):
                stop_extraction = True
                break
            
            # è·³è¿‡å…ƒæ•°æ®è¡Œ
            if any(skip in line_stripped for skip in [
                'åŒºåŸŸ', 'ä½ç½®:', 'ç½®ä¿¡åº¦:', 'è¯†åˆ«ç»“æœå¦‚ä¸‹', 'æ ¹æ®OCR', 'æ ¹æ®è¯†åˆ«'
            ]):
                continue
            
            # æå–å®é™…æ–‡å­—ï¼ˆåœ¨æ–‡å­—å†…å®¹sectionä¸­ï¼Œä¸”æœªåœæ­¢ï¼‰
            if in_text_section and not stop_extraction and line_stripped:
                # è·³è¿‡ç©ºè¡Œã€åˆ†éš”çº¿ã€åˆ—è¡¨æ ‡è®°è¡Œ
                if (line_stripped.startswith('---') or 
                    line_stripped.startswith('```') or
                    line_stripped == '**' or
                    (line_stripped.startswith('-') and len(line_stripped) < 50) or
                    (line_stripped[0].isdigit() and '. ' in line_stripped[:3])):  # è·³è¿‡ç¼–å·åˆ—è¡¨
                    continue
                
                # ç§»é™¤markdownæ ¼å¼ï¼Œä¿ç•™æ–‡å­—
                clean_line = line_stripped.replace('**', '').replace('```', '').strip()
                
                # ç§»é™¤å¸¸è§çš„å‰ç¼€
                for prefix in ['è¯†åˆ«ç»“æœæ˜¾ç¤ºå›¾ç‰‡ä¸­çš„æ–‡å­—æ˜¯', 'è¯†åˆ«ç»“æœæ˜¾ç¤ºå›¾ç‰‡ä¸­åªæœ‰ä¸€ä¸ªå•è¯ï¼š', 
                               'è¯†åˆ«ç»“æœæ˜¾ç¤ºå›¾ç‰‡ä¸­', 'è¯†åˆ«ç»“æœåªæœ‰ä¸€ä¸ªå•è¯ï¼š', 'è¯†åˆ«ç»“æœï¼š',
                               'è¯†åˆ«ç»“æœæ˜¾ç¤º', 'è¯†åˆ«ç»“æœå¦‚ä¸‹ï¼š']:
                    if clean_line.startswith(prefix):
                        clean_line = clean_line[len(prefix):].strip()
                        # ç§»é™¤å¯èƒ½å­˜åœ¨çš„å¼•å·
                        clean_line = clean_line.strip('"').strip("'").strip()
                        break
                
                # æˆªæ–­è§£é‡Šæ€§åç¼€ï¼ˆå¦‚"ï¼Œç½®ä¿¡åº¦ä¸º..."ï¼‰
                for suffix_marker in ['ï¼Œç½®ä¿¡åº¦', 'ã€‚ç½®ä¿¡åº¦', 'ï¼Œè¡¨ç¤º', 'ã€‚è¡¨ç¤º', 'ï¼Œè¿™æ˜¯', 'ï¼Œæ„æ€æ˜¯']:
                    if suffix_marker in clean_line:
                        clean_line = clean_line.split(suffix_marker)[0].strip()
                        break
                
                # å†æ¬¡æ¸…ç†å¯èƒ½æ®‹ç•™çš„å¼•å·
                clean_line = clean_line.strip('"').strip("'").strip()
                
                if clean_line:
                    text_lines.append(clean_line)
                    
                    # é™åˆ¶æå–çš„è¡Œæ•°ï¼ˆå‰3-5è¡Œé€šå¸¸æ˜¯ä¸»è¦å†…å®¹ï¼‰
                    if len(text_lines) >= 5:
                        break
        
        # åˆå¹¶æ–‡å­—
        if not text_lines:
            return ""
        
        full_text = ' '.join(text_lines)
        
        # é™åˆ¶é•¿åº¦
        if len(full_text) > 200:
            full_text = full_text[:200] + '...'
        
        return full_text
    
    
    def save_summary(self, summary: Dict, output_path: str):
        """ä¿å­˜æ‘˜è¦åˆ°JSONæ–‡ä»¶"""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        print(f"âœ“ æ‘˜è¦å·²ä¿å­˜åˆ°: {output_path}")


def test_summarizer():
    """æµ‹è¯•æ‘˜è¦å™¨"""
    # æµ‹è¯•æ–‡ä»¶
    test_file = "case2_output/example1_result.json"
    
    if not Path(test_file).exists():
        print(f"æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
        return
    
    print("=" * 80)
    print("æµ‹è¯• ResultSummarizer")
    print("=" * 80)
    
    # åˆ›å»ºæ‘˜è¦å™¨
    summarizer = ResultSummarizer(max_ocr_text_length=800)
    
    # æå–æ‘˜è¦
    print("\n1. æå–å…³é”®ä¿¡æ¯...")
    summary = summarizer.summarize_from_file(test_file)
    
    # ä¿å­˜æ‘˜è¦JSON
    summary_json_path = "case2_output/example1_summary.json"
    summarizer.save_summary(summary, summary_json_path)
    
    # æ ¼å¼åŒ–ä¸ºæç¤ºæ–‡æœ¬
    print("\n2. æ ¼å¼åŒ–ä¸ºå¤§æ¨¡å‹æç¤ºæ–‡æœ¬...")
    prompt = summarizer.format_as_prompt(summary)
    
    # ä¿å­˜æç¤ºæ–‡æœ¬
    prompt_txt_path = "case2_output/example1_prompt.txt"
    with open(prompt_txt_path, 'w', encoding='utf-8') as f:
        f.write(prompt)
    print(f"âœ“ æç¤ºæ–‡æœ¬å·²ä¿å­˜åˆ°: {prompt_txt_path}")
    
    # æ‰“å°æç¤ºæ–‡æœ¬
    print("\n" + "=" * 80)
    print("ç”Ÿæˆçš„æç¤ºæ–‡æœ¬:")
    print("=" * 80)
    print(prompt)
    print("=" * 80)
    
    # ç»Ÿè®¡ä¿¡æ¯
    print(f"\næ‘˜è¦ç»Ÿè®¡:")
    print(f"- åŸå§‹JSONå¤§å°: {Path(test_file).stat().st_size / 1024:.2f} KB")
    print(f"- æ‘˜è¦JSONå¤§å°: {Path(summary_json_path).stat().st_size / 1024:.2f} KB")
    print(f"- æç¤ºæ–‡æœ¬å¤§å°: {Path(prompt_txt_path).stat().st_size / 1024:.2f} KB")
    print(f"- å‹ç¼©æ¯”ä¾‹: {Path(summary_json_path).stat().st_size / Path(test_file).stat().st_size * 100:.1f}%")


if __name__ == "__main__":
    test_summarizer()

