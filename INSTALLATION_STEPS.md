# Pipeline ç¯å¢ƒå®‰è£…æ­¥éª¤ï¼ˆä»0å¼€å§‹ï¼‰

**å®Œæ•´çš„æ“ä½œå‘½ä»¤åˆ—è¡¨ï¼ŒæŒ‰é¡ºåºæ‰§è¡Œå³å¯ã€‚**

---

## å‰ææ¡ä»¶

- æ“ä½œç³»ç»Ÿ: Ubuntu 20.04/22.04 (æ¨è)
- GPU: NVIDIA GPU (8GB+ æ˜¾å­˜)
- ç£ç›˜ç©ºé—´: 50GB ä»¥ä¸Š

---

## ç¬¬ä¸€æ­¥ï¼šç³»ç»Ÿå‡†å¤‡

### 1.1 å®‰è£… NVIDIA é©±åŠ¨å’Œ CUDA

```bash
# æ£€æŸ¥æ˜¯å¦å·²å®‰è£…
nvidia-smi

# å¦‚æœæœªå®‰è£…ï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤
# Ubuntu 22.04
sudo apt update
sudo apt install nvidia-driver-525
sudo apt install nvidia-cuda-toolkit

# é‡å¯
sudo reboot

# é‡å¯åéªŒè¯
nvidia-smi
nvcc --version
```

### 1.2 å®‰è£…ç³»ç»Ÿä¾èµ–

```bash
sudo apt update
sudo apt install -y \
    python3.10 \
    python3.10-venv \
    python3-pip \
    git \
    git-lfs \
    wget \
    curl \
    build-essential
```

---

## ç¬¬äºŒæ­¥ï¼šå…‹éš†é¡¹ç›®

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/YOUR_USERNAME/YOUR_REPO.git
cd YOUR_REPO

# æˆ–è€…å¦‚æœå·²æœ‰é¡¹ç›®æ–‡ä»¶å¤¹
cd /root/program2
```

---

## ç¬¬ä¸‰æ­¥ï¼šåˆ›å»º Python è™šæ‹Ÿç¯å¢ƒ

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3.10 -m venv venv

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source venv/bin/activate

# å‡çº§ pip
pip install --upgrade pip setuptools wheel
```

---

## ç¬¬å››æ­¥ï¼šå®‰è£… PyTorch

### 4.1 ç¡®å®š CUDA ç‰ˆæœ¬

```bash
nvcc --version
# è®°ä¸‹ CUDA ç‰ˆæœ¬ï¼Œä¾‹å¦‚ 11.8 æˆ– 12.1
```

### 4.2 å®‰è£…å¯¹åº”ç‰ˆæœ¬çš„ PyTorch

**CUDA 11.8:**
```bash
pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 \
  --index-url https://download.pytorch.org/whl/cu118
```

**CUDA 12.1:**
```bash
pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 \
  --index-url https://download.pytorch.org/whl/cu121
```

**éªŒè¯å®‰è£…:**
```bash
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}')"
```

é¢„æœŸè¾“å‡º:
```
PyTorch: 2.1.0+cu118
CUDA available: True
```

---

## ç¬¬äº”æ­¥ï¼šå®‰è£…å…¶ä»– Python ä¾èµ–

```bash
# å®‰è£… requirements.txt ä¸­çš„æ‰€æœ‰åŒ…
pip install -r requirements.txt

# å¦‚æœæŸäº›åŒ…å®‰è£…å¤±è´¥ï¼Œå•ç‹¬å®‰è£…
pip install transformers==4.40.0
pip install accelerate==0.25.0
pip install qwen-vl-utils
pip install paddlepaddle-gpu==2.5.0
pip install paddleocr==2.7.0
pip install Pillow opencv-python numpy
pip install sentencepiece protobuf regex
pip install tqdm pandas requests
pip install huggingface-hub
```

**éªŒè¯å®‰è£…:**
```bash
pip list | grep -E "torch|transformers|paddleocr|qwen"
```

---

## ç¬¬å…­æ­¥ï¼šä¸‹è½½æ¨¡å‹æ–‡ä»¶

### 6.1 å®‰è£… HuggingFace CLI

```bash
pip install huggingface-hub[cli]

# éªŒè¯
huggingface-cli --version
```

### 6.2 åˆ›å»ºæ¨¡å‹ç›®å½•

```bash
mkdir -p models
mkdir -p checkpoints
```

### 6.3 ä¸‹è½½ Phi-3.5-Vision (8GB)

**æ¨¡å‹åç§°**: `microsoft/Phi-3.5-vision-instruct`

```bash
huggingface-cli download microsoft/Phi-3.5-vision-instruct \
  --local-dir models/phi-3_5_vision \
  --local-dir-use-symlinks False
```

**éªŒè¯:**
```bash
ls -lh models/phi-3_5_vision/
# åº”è¯¥çœ‹åˆ° model-00001-of-00002.safetensors (4.7GB)
#          model-00002-of-00002.safetensors (3.2GB)
#          config.json
#          ç­‰å…¶ä»–æ–‡ä»¶
```

### 6.4 ä¸‹è½½ Qwen2-VL-2B (5GB)

**æ¨¡å‹åç§°**: `Qwen/Qwen2-VL-2B-Instruct`

```bash
huggingface-cli download Qwen/Qwen2-VL-2B-Instruct \
  --local-dir models/Qwen2-VL-2B-Instruct \
  --local-dir-use-symlinks False
```

**éªŒè¯:**
```bash
ls -lh models/Qwen2-VL-2B-Instruct/
# åº”è¯¥çœ‹åˆ° model-00001-of-00002.safetensors (3.8GB)
#          model-00002-of-00002.safetensors (410MB)
#          config.json
#          ç­‰å…¶ä»–æ–‡ä»¶
```

### 6.5 ä¸‹è½½ TrOCR (2.5GB)

**æ¨¡å‹åç§°**: `microsoft/trocr-base-handwritten`

```bash
huggingface-cli download microsoft/trocr-base-handwritten \
  --local-dir trocr-base-handwritten \
  --local-dir-use-symlinks False
```

**éªŒè¯:**
```bash
ls -lh trocr-base-handwritten/
# åº”è¯¥çœ‹åˆ° model.safetensors (1.3GB)
#          pytorch_model.bin (1.3GB)
#          config.json
#          ç­‰å…¶ä»–æ–‡ä»¶

---

## ç¬¬ä¸ƒæ­¥ï¼šè·å–åˆ†ç±»å™¨ Checkpoint

### æ–¹æ³• 1: è‡ªå·±è®­ç»ƒï¼ˆéœ€è¦è®­ç»ƒæ•°æ®ï¼‰

```bash
# å¦‚æœæœ‰è®­ç»ƒæ•°æ®å’Œè®­ç»ƒè„šæœ¬
python printed_vs_hand_main.py --train
```

### æ–¹æ³• 2: ä»æä¾›çš„ä½ç½®ä¸‹è½½ï¼ˆå¦‚æœæœ‰ï¼‰

```bash
# ç¤ºä¾‹ï¼šä»ç½‘ç›˜ä¸‹è½½
wget YOUR_DOWNLOAD_LINK -O checkpoints/printed_vs_hand_best.pth

# æˆ–ä½¿ç”¨ curl
curl -L YOUR_DOWNLOAD_LINK -o checkpoints/printed_vs_hand_best.pth
```

### æ–¹æ³• 3: ä¸´æ—¶è·³è¿‡ï¼ˆä»…ç”¨äºæµ‹è¯•ï¼‰

```bash
# åˆ›å»ºä¸€ä¸ªå ä½æ–‡ä»¶ï¼ˆä¸æ¨èï¼Œä½†å¯ç”¨äºæµ‹è¯•ï¼‰
touch checkpoints/printed_vs_hand_best.pth
```

**éªŒè¯:**
```bash
ls -lh checkpoints/
# åº”è¯¥çœ‹åˆ° printed_vs_hand_best.pth (43MB)
```

---

## ç¬¬å…«æ­¥ï¼šéªŒè¯å®‰è£…

### 8.1 æ£€æŸ¥ Python ç¯å¢ƒ

```bash
python --version
# è¾“å‡º: Python 3.10.x
```

### 8.2 æ£€æŸ¥ PyTorch å’Œ CUDA

```bash
python << EOF
import torch
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"CUDA version: {torch.version.cuda}")
print(f"GPU count: {torch.cuda.device_count()}")
if torch.cuda.is_available():
    print(f"GPU name: {torch.cuda.get_device_name(0)}")
    print(f"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
EOF
```

**é¢„æœŸè¾“å‡º:**
```
PyTorch version: 2.1.0+cu118
CUDA available: True
CUDA version: 11.8
GPU count: 1
GPU name: NVIDIA GeForce RTX 3090
GPU memory: 24.0 GB
```

### 8.3 æ£€æŸ¥ä¾èµ–åŒ…

```bash
python << EOF
packages = {
    'transformers': 'transformers',
    'accelerate': 'accelerate', 
    'paddleocr': 'paddleocr',
    'qwen_vl_utils': 'qwen-vl-utils',
    'PIL': 'Pillow',
    'cv2': 'opencv-python',
}

for module_name, package_name in packages.items():
    try:
        if module_name == 'PIL':
            import PIL
            print(f"âœ“ {package_name}: {PIL.__version__}")
        elif module_name == 'cv2':
            import cv2
            print(f"âœ“ {package_name}: {cv2.__version__}")
        else:
            module = __import__(module_name)
            version = getattr(module, '__version__', 'installed')
            print(f"âœ“ {package_name}: {version}")
    except ImportError:
        print(f"âœ— {package_name}: NOT INSTALLED")
EOF
```

### 8.4 æ£€æŸ¥æ¨¡å‹æ–‡ä»¶

```bash
python << EOF
from pathlib import Path

models = [
    ('models/phi-3_5_vision', 'Phi-3.5-Vision'),
    ('models/Qwen2-VL-2B-Instruct', 'Qwen2-VL-2B'),
    ('trocr-base-handwritten', 'TrOCR'),
    ('checkpoints/printed_vs_hand_best.pth', 'Classifier'),
]

print("Model files check:")
for path, name in models:
    p = Path(path)
    if p.exists():
        if p.is_dir():
            size = sum(f.stat().st_size for f in p.rglob('*') if f.is_file())
            size_gb = size / 1024**3
            print(f"âœ“ {name}: {size_gb:.1f} GB")
        else:
            size_mb = p.stat().st_size / 1024**2
            print(f"âœ“ {name}: {size_mb:.1f} MB")
    else:
        print(f"âœ— {name}: NOT FOUND")
EOF
```

**é¢„æœŸè¾“å‡º:**
```
Model files check:
âœ“ Phi-3.5-Vision: 8.0 GB
âœ“ Qwen2-VL-2B: 5.0 GB
âœ“ TrOCR: 2.5 GB
âœ“ Classifier: 43.0 MB
```

### 8.5 æµ‹è¯•è¿è¡Œ

```bash
# åˆ›å»ºæµ‹è¯•å›¾ç‰‡ï¼ˆå¦‚æœæ²¡æœ‰ï¼‰
mkdir -p test_images

# æµ‹è¯• Phi3.5 Pipeline
python case2/pipeline.py \
  --image test_images/sample.jpg \
  --query "What is written in the image?" \
  --output test_output.json \
  --limit 1

# æ£€æŸ¥è¾“å‡º
cat test_output.json
```

**é¢„æœŸ**: åº”è¯¥æˆåŠŸç”Ÿæˆ JSON æ–‡ä»¶ï¼ŒåŒ…å«è¯†åˆ«ç»“æœã€‚

---

## ç¬¬ä¹æ­¥ï¼šé¦–æ¬¡è¿è¡Œæ³¨æ„äº‹é¡¹

### 9.1 PaddleOCR æ¨¡å‹è‡ªåŠ¨ä¸‹è½½

**ç¬¬ä¸€æ¬¡è¿è¡Œ pipeline æ—¶ï¼ŒPaddleOCR ä¼šè‡ªåŠ¨ä¸‹è½½ä»¥ä¸‹æ¨¡å‹:**

1. **PP-OCRv5_server_det** (~50 MB) - æ–‡å­—æ£€æµ‹æ¨¡å‹
2. **en_PP-OCRv5_mobile_rec** (~10 MB) - è‹±æ–‡è¯†åˆ«æ¨¡å‹

**ä¸‹è½½ä½ç½®:** `~/.paddlex/official_models/`

**é¦–æ¬¡è¿è¡Œå‘½ä»¤:**
```bash
python case2/pipeline.py \
  --image test_images/sample.jpg \
  --query "What is written?" \
  --output test.json
```

**é¢„æœŸè¡Œä¸º:**
```
Creating model: ('PP-OCRv5_server_det', None)
Downloading model files...  [ä¸‹è½½è¿›åº¦æ¡]
Creating model: ('en_PP-OCRv5_mobile_rec', None)
Downloading model files...  [ä¸‹è½½è¿›åº¦æ¡]
```

**ç­‰å¾…ä¸‹è½½å®Œæˆå³å¯ï¼Œä¸‹æ¬¡è¿è¡Œå°±ä¸ä¼šå†ä¸‹è½½ã€‚**

### 9.2 å¸ƒå±€æ£€æµ‹æ¨¡å‹è‡ªåŠ¨ä¸‹è½½

**å¦‚æœ pipeline éœ€è¦å¸ƒå±€æ£€æµ‹ï¼Œä¼šè‡ªåŠ¨ä¸‹è½½:**

**PP-DocLayout_plus-L** (~124 MB)

**ä¸‹è½½ä½ç½®:** `layoutModel/` æˆ– PaddlePaddle ç¼“å­˜ç›®å½•

---

## å®Œæ•´çš„æ¨¡å‹æ¸…å•

### éœ€è¦æ‰‹åŠ¨ä¸‹è½½çš„æ¨¡å‹

| æ¨¡å‹åç§° | HuggingFace ä»“åº“ | æœ¬åœ°è·¯å¾„ | å¤§å° | å¿…éœ€ |
|---------|-----------------|---------|------|------|
| Phi-3.5-Vision | `microsoft/Phi-3.5-vision-instruct` | `models/phi-3_5_vision/` | 8 GB | âœ… Phi3.5 Pipeline |
| Qwen2-VL-2B | `Qwen/Qwen2-VL-2B-Instruct` | `models/Qwen2-VL-2B-Instruct/` | 5 GB | âœ… Qwen Pipeline |
| Qwen2-VL-7B | `Qwen/Qwen2-VL-7B-Instruct` | `models/Qwen2-VL-7B-Instruct/` | 15 GB | âŒ å¯é€‰ |
| TrOCR | `microsoft/trocr-base-handwritten` | `trocr-base-handwritten/` | 2.5 GB | âœ… æ‰‹å†™è¯†åˆ« |
| åˆ†ç±»å™¨ | (éœ€è‡ªå·±è®­ç»ƒæˆ–è·å–) | `checkpoints/printed_vs_hand_best.pth` | 43 MB | âœ… åˆ†ç±»å™¨ |

### è‡ªåŠ¨ä¸‹è½½çš„æ¨¡å‹

| æ¨¡å‹åç§° | ä¸‹è½½æ—¶æœº | ä¸‹è½½ä½ç½® | å¤§å° |
|---------|---------|---------|------|
| PP-OCRv5_server_det | é¦–æ¬¡è¿è¡Œ | `~/.paddlex/official_models/` | 50 MB |
| en_PP-OCRv5_mobile_rec | é¦–æ¬¡è¿è¡Œ | `~/.paddlex/official_models/` | 10 MB |
| PP-DocLayout_plus-L | é¦–æ¬¡å¸ƒå±€æ£€æµ‹ | `layoutModel/` | 124 MB |

---

## å¿«é€Ÿå®‰è£…è„šæœ¬

å°†ä»¥ä¸‹å†…å®¹ä¿å­˜ä¸º `quick_install.sh`:

```bash
#!/bin/bash
set -e

echo "================================"
echo "Pipeline ç¯å¢ƒå¿«é€Ÿå®‰è£…"
echo "================================"

# 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
echo "Step 1: åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ..."
python3.10 -m venv venv
source venv/bin/activate

# 2. å‡çº§ pip
echo "Step 2: å‡çº§ pip..."
pip install --upgrade pip setuptools wheel

# 3. å®‰è£… PyTorch (CUDA 11.8)
echo "Step 3: å®‰è£… PyTorch..."
pip install torch==2.1.0 torchvision==0.16.0 \
  --index-url https://download.pytorch.org/whl/cu118

# 4. å®‰è£…ä¾èµ–
echo "Step 4: å®‰è£…ä¾èµ–åŒ…..."
pip install -r requirements.txt

# 5. åˆ›å»ºç›®å½•
echo "Step 5: åˆ›å»ºæ¨¡å‹ç›®å½•..."
mkdir -p models checkpoints

# 6. ä¸‹è½½æ¨¡å‹
echo "Step 6: ä¸‹è½½æ¨¡å‹ (è¿™å°†éœ€è¦ä¸€äº›æ—¶é—´)..."

echo "  - ä¸‹è½½ Phi-3.5-Vision (8GB)..."
huggingface-cli download microsoft/Phi-3.5-vision-instruct \
  --local-dir models/phi-3_5_vision \
  --local-dir-use-symlinks False

echo "  - ä¸‹è½½ Qwen2-VL-2B (5GB)..."
huggingface-cli download Qwen/Qwen2-VL-2B-Instruct \
  --local-dir models/Qwen2-VL-2B-Instruct \
  --local-dir-use-symlinks False

echo "  - ä¸‹è½½ TrOCR (2.5GB)..."
huggingface-cli download microsoft/trocr-base-handwritten \
  --local-dir trocr-base-handwritten \
  --local-dir-use-symlinks False

echo ""
echo "================================"
echo "âœ“ å®‰è£…å®Œæˆï¼"
echo "================================"
echo ""
echo "âš ï¸  æ³¨æ„äº‹é¡¹:"
echo "1. åˆ†ç±»å™¨ checkpoint éœ€è¦å•ç‹¬è·å–"
echo "   ä½ç½®: checkpoints/printed_vs_hand_best.pth"
echo ""
echo "2. PaddleOCR æ¨¡å‹ä¼šåœ¨é¦–æ¬¡è¿è¡Œæ—¶è‡ªåŠ¨ä¸‹è½½"
echo ""
echo "3. æµ‹è¯•å®‰è£…:"
echo "   python case2/pipeline.py --image test.jpg --query 'What is this?'"
echo ""
```

è¿è¡Œè„šæœ¬:
```bash
chmod +x quick_install.sh
./quick_install.sh
```

---

## æ•…éšœæ’é™¤

### é—®é¢˜ 1: huggingface-cli ä¸‹è½½å¾ˆæ…¢

**è§£å†³æ–¹æ¡ˆ: ä½¿ç”¨é•œåƒ**
```bash
export HF_ENDPOINT=https://hf-mirror.com
huggingface-cli download microsoft/Phi-3.5-vision-instruct \
  --local-dir models/phi-3_5_vision
```

### é—®é¢˜ 2: CUDA out of memory

**è§£å†³æ–¹æ¡ˆ: ä½¿ç”¨ Qwen2-VL-2B è€Œä¸æ˜¯ 7B**
```bash
# ç¡®ä¿ä¸‹è½½çš„æ˜¯ 2B ç‰ˆæœ¬
ls -lh models/Qwen2-VL-2B-Instruct/
```

### é—®é¢˜ 3: ImportError: cannot import name 'XXX'

**è§£å†³æ–¹æ¡ˆ: é‡æ–°å®‰è£…ä¾èµ–**
```bash
pip install -r requirements.txt --force-reinstall
```

### é—®é¢˜ 4: PaddleOCR ä¸‹è½½æ¨¡å‹å¤±è´¥

**è§£å†³æ–¹æ¡ˆ: æ‰‹åŠ¨ä¸‹è½½**
```bash
# PaddleOCR ä¼šåœ¨é¦–æ¬¡è¿è¡Œæ—¶è‡ªåŠ¨ä¸‹è½½
# å¦‚æœå¤±è´¥ï¼Œç­‰å¾…é‡è¯•æˆ–æ£€æŸ¥ç½‘ç»œ
```

---

## å®Œæˆæ£€æŸ¥æ¸…å•

å®‰è£…å®Œæˆåï¼Œæ£€æŸ¥ä»¥ä¸‹é¡¹ç›®:

- [ ] Python 3.10+ å·²å®‰è£…
- [ ] CUDA 11.8+ å¯ç”¨ (`nvidia-smi`)
- [ ] è™šæ‹Ÿç¯å¢ƒå·²åˆ›å»ºå¹¶æ¿€æ´»
- [ ] PyTorch å·²å®‰è£… (`torch.cuda.is_available()` è¿”å› True)
- [ ] requirements.txt æ‰€æœ‰åŒ…å·²å®‰è£…
- [ ] Phi-3.5-Vision å·²ä¸‹è½½ (8GB)
- [ ] Qwen2-VL-2B å·²ä¸‹è½½ (5GB)
- [ ] TrOCR å·²ä¸‹è½½ (2.5GB)
- [ ] åˆ†ç±»å™¨ checkpoint å·²è·å– (43MB)
- [ ] æµ‹è¯•è¿è¡ŒæˆåŠŸ

---

## ä¸‹ä¸€æ­¥

å®‰è£…å®Œæˆåï¼Œå¯ä»¥:

1. **è¿è¡Œ Phi3.5 Pipeline:**
   ```bash
   python case2/pipeline.py --image your_image.jpg --query "your question"
   ```

2. **è¿è¡Œ Qwen Pipeline:**
   ```bash
   python qwen_version/pipeline.py --image your_image.jpg --query "your question"
   ```

3. **æ‰¹é‡å¤„ç†:**
   ```bash
   python case2/pipeline.py --json dataset.json --output results.json
   ```

---

## æ€»ç»“

**å®‰è£…æ—¶é—´ä¼°ç®—:**
- ä¾èµ–åŒ…å®‰è£…: 10-20 åˆ†é’Ÿ
- æ¨¡å‹ä¸‹è½½: 1-2 å°æ—¶ (å–å†³äºç½‘é€Ÿ)
- æ€»è®¡: 1.5-2.5 å°æ—¶

**ç£ç›˜ç©ºé—´ä½¿ç”¨:**
- Python ç¯å¢ƒ: ~5 GB
- æ¨¡å‹æ–‡ä»¶: ~16 GB
- æ€»è®¡: ~21 GB

**æ˜¾å­˜éœ€æ±‚:**
- Phi3.5 Pipeline: 8-10 GB
- Qwen2-VL-2B Pipeline: 6-8 GB
- åŒæ—¶è¿è¡Œ: ä¸å»ºè®®

ç¥å®‰è£…é¡ºåˆ©ï¼ğŸš€
