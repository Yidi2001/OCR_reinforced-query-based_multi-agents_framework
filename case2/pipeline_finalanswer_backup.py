#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Multi-Agent OCR Pipeline
å®Œæ•´çš„æ™ºèƒ½ OCR å¤„ç†æµç¨‹ï¼šè‡ªåŠ¨åˆ¤æ–­å›¾ç‰‡ç±»å‹å¹¶è°ƒç”¨å¯¹åº”çš„ Agent
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))
sys.path.insert(0, str(Path(__file__).parent))

from case2.orchestrator import MultiAgentOrchestrator
from case2.result_summarizer import ResultSummarizer
from case2.merge_layout_blocks_ratio import merge_layout_regions_ratio_dedup_v2
from case2.token_budget_calculator import TokenBudgetCalculator
from case2.phi_refiner import PhiRefiner
import json
import re
import math
import hashlib


def process_image(image_path: str, query: str, output_path: str = None, example_name: str = None, 
                  generate_summary: bool = True, enable_refinement: bool = True, 
                  auto_token_budget: bool = True, verbose: bool = True, sample_output_dir: str = None,
                  orchestrator: 'MultiAgentOrchestrator' = None, refiner: 'PhiRefiner' = None):
    """
    å¤„ç†å•å¼ å›¾ç‰‡çš„å®Œæ•´æµç¨‹
    
    Pipeline å·¥ä½œæµç¨‹ï¼š
    1. Target Detection - è‡ªåŠ¨åˆ¤æ–­å›¾ç‰‡ç±»å‹ï¼ˆæ‰‹å†™ä½“/å°åˆ·ä½“ï¼‰
    2. Task Planning - Phi3.5-Vision åˆ†æå›¾ç‰‡è´¨é‡å’Œå¤æ‚åº¦
    3. Prompt Generation - ç”Ÿæˆç»“æ„åŒ–æ‰§è¡Œè®¡åˆ’
    4. Agent Execution - æ ¹æ®è®¡åˆ’è‡ªåŠ¨é€‰æ‹©å¹¶æ‰§è¡Œå¯¹åº”çš„ Agent
    5. Layout Integration - æ•´åˆå¸ƒå±€æ£€æµ‹ç»“æœ
    6. Summary Generation - è‡ªåŠ¨ç”Ÿæˆå…³é”®ä¿¡æ¯æ‘˜è¦
    7. Layout Selection - æ ¹æ®ç›¸å…³æ€§é€‰æ‹©å¸ƒå±€åŒºåŸŸï¼ˆå¯é€‰ï¼‰
    8. Answer Refinement - ä½¿ç”¨ Phi3.5-Vision ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆï¼ˆå¯é€‰ï¼‰
    
    Args:
        image_path: å›¾ç‰‡è·¯å¾„
        query: ç”¨æˆ·æŸ¥è¯¢/ä»»åŠ¡æè¿°
        output_path: è¾“å‡ºç»“æœè·¯å¾„ï¼ˆå¯é€‰ï¼‰
        example_name: ä»»åŠ¡åç§°ï¼ˆå¯é€‰ï¼‰
        generate_summary: æ˜¯å¦è‡ªåŠ¨ç”Ÿæˆæ‘˜è¦ï¼ˆé»˜è®¤Trueï¼‰
        enable_refinement: æ˜¯å¦å¯ç”¨æœ€ç»ˆç­”æ¡ˆç”Ÿæˆï¼ˆé»˜è®¤Trueï¼‰
        auto_token_budget: æ˜¯å¦è‡ªåŠ¨è®¡ç®— token é¢„ç®—ï¼ˆé»˜è®¤Trueï¼‰
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¾“å‡ºï¼ˆé»˜è®¤Trueï¼‰
        sample_output_dir: æ ·æœ¬ä¸“å±è¾“å‡ºç›®å½•ï¼ˆç”¨äºä¿å­˜å¯è§†åŒ–å›¾ç‰‡ç­‰ï¼‰
        orchestrator: å¤ç”¨çš„ orchestrator å®ä¾‹ï¼ˆå¯é€‰ï¼Œç”¨äºæ‰¹å¤„ç†æ—¶é¿å…é‡å¤åŠ è½½æ¨¡å‹ï¼‰
        refiner: å¤ç”¨çš„ refiner å®ä¾‹ï¼ˆå¯é€‰ï¼Œç”¨äºæ‰¹å¤„ç†æ—¶é¿å…é‡å¤åŠ è½½æ¨¡å‹ï¼‰
    
    Returns:
        æ‰§è¡Œç»“æœå­—å…¸ï¼ŒåŒ…å«åˆ†ç±»ã€è§„åˆ’ã€æ‰§è¡Œç»“æœå’Œæœ€ç»ˆç­”æ¡ˆ
    """
    if example_name and verbose:
        print("\n" + "="*70)
        print(f" " * 20 + f"ä»»åŠ¡: {example_name}")
        print("="*70)
    
    if not Path(image_path).exists():
        if verbose:
            print(f"âŒ é”™è¯¯ï¼šå›¾ç‰‡ä¸å­˜åœ¨ - {image_path}")
        return None
    
    # åˆ›å»ºæˆ–å¤ç”¨ç¼–æ’å™¨
    if orchestrator is None:
        orchestrator = MultiAgentOrchestrator(execute_agents=True)
    
    # è¿è¡Œå®Œæ•´æµç¨‹ï¼ˆå¦‚æœ verbose=Falseï¼ŒæŠ‘åˆ¶è¾“å‡ºï¼‰
    import sys
    from io import StringIO
    
    if verbose:
        result = orchestrator.run(
            image_path=image_path,
            query=query,
            output_path=output_path,
            sample_output_dir=sample_output_dir
        )
    else:
        # ä¸´æ—¶é‡å®šå‘ stdout æ¥æŠ‘åˆ¶è¾“å‡º
        old_stdout = sys.stdout
        sys.stdout = StringIO()
        try:
            result = orchestrator.run(
                image_path=image_path,
                query=query,
                output_path=output_path,
                sample_output_dir=sample_output_dir
            )
        finally:
            sys.stdout = old_stdout
    
    # å¦‚æœæœ‰å¸ƒå±€æ£€æµ‹ç»“æœï¼Œå…ˆè¿›è¡Œå¸ƒå±€æ•´åˆ
    if result:
        result = _integrate_layout_results(result, image_path, verbose=verbose)
    
    # è‡ªåŠ¨ç”Ÿæˆæ‘˜è¦
    if generate_summary and result:
        try:
            if verbose:
                print("\nğŸ“Š ç”Ÿæˆç»“æœæ‘˜è¦...")
            summarizer = ResultSummarizer(max_ocr_text_length=800)
            
            # ç”Ÿæˆæ‘˜è¦JSONï¼ˆå¦‚æœåœ¨æ ·æœ¬æ–‡ä»¶å¤¹ä¸­ï¼Œä½¿ç”¨æ›´ç®€æ´çš„åç§°ï¼‰
            if sample_output_dir and output_path and output_path.startswith(sample_output_dir):
                summary_json_path = str(Path(sample_output_dir) / "summary.json")
                prompt_txt_path = str(Path(sample_output_dir) / "prompt.txt")
            elif output_path:
                summary_json_path = output_path.replace('.json', '_summary.json')
                prompt_txt_path = output_path.replace('.json', '_prompt.txt')
            else:
                # æ‰¹é‡å¤„ç†æ¨¡å¼ï¼šä½¿ç”¨ä¸´æ—¶è·¯å¾„ï¼ˆä¸å®é™…ä¿å­˜ï¼‰
                import tempfile
                temp_id = id(result)
                summary_json_path = str(Path(tempfile.gettempdir()) / f"summary_{temp_id}.json")
                prompt_txt_path = str(Path(tempfile.gettempdir()) / f"prompt_{temp_id}.txt")
            
            summary = summarizer.summarize(result)
            summarizer.save_summary(summary, summary_json_path)
            
            # ç”Ÿæˆæç¤ºæ–‡æœ¬
            prompt = summarizer.format_as_prompt(summary)
            with open(prompt_txt_path, 'w', encoding='utf-8') as f:
                f.write(prompt)
            if verbose:
                print(f"âœ“ æç¤ºæ–‡æœ¬å·²ä¿å­˜åˆ°: {prompt_txt_path}")
            
            # æ·»åŠ æ‘˜è¦ä¿¡æ¯åˆ°ç»“æœ
            result['summary_files'] = {
                'summary_json': summary_json_path,
                'prompt_txt': prompt_txt_path
            }
            
        except Exception as e:
            print(f"\nâš ï¸  ç”Ÿæˆæ‘˜è¦å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            # æ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œè®¾ç½®å˜é‡ä¸º Noneï¼Œåç»­æ­¥éª¤ä¼šè·³è¿‡
            summary = None
            summary_json_path = None
        
        # æ­¥éª¤ 7 & 8: ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆï¼ˆç‹¬ç«‹çš„ try-exceptï¼‰
        if enable_refinement:
            try:
                # å¦‚æœæ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡æœ€ç»ˆç­”æ¡ˆç”Ÿæˆ
                if summary is None or summary_json_path is None:
                    if verbose:
                        print("âš ï¸  è·³è¿‡æœ€ç»ˆç­”æ¡ˆç”Ÿæˆï¼šæ‘˜è¦ç”Ÿæˆå¤±è´¥")
                    return result
                
                layout_result = result.get('execution_results', {}).get('layout_result')
                has_layout = layout_result and layout_result.get('detected_regions', 0) > 0
                
                if has_layout:
                    # å¤æ‚åœºæ™¯ï¼šå…ˆé€‰æ‹©ç›¸å…³å¸ƒå±€ï¼Œå†ç”Ÿæˆç­”æ¡ˆ
                    if verbose:
                        print("\nğŸ“‹ æ­¥éª¤ 7: é€‰æ‹©ç›¸å…³å¸ƒå±€åŒºåŸŸ...")
                    
                    # ç”Ÿæˆæ–‡ä»¶å
                    if sample_output_dir and output_path and output_path.startswith(sample_output_dir):
                        selected_layout_path = str(Path(sample_output_dir) / "selected_layout.json")
                    elif output_path:
                        selected_layout_path = output_path.replace('.json', '_selected_layout.json')
                    else:
                        # æ‰¹é‡å¤„ç†æ¨¡å¼ï¼šä½¿ç”¨ä¸´æ—¶è·¯å¾„ï¼ˆä¸å®é™…ä¿å­˜ï¼‰
                        import tempfile
                        selected_layout_path = str(Path(tempfile.gettempdir()) / f"selected_layout_{id(summary)}.json")
                    
                    selected_layout = _select_relevant_layouts(
                        summary, 
                        image_path, 
                        selected_layout_path,
                        auto_token_budget=auto_token_budget,
                        verbose=verbose
                    )
                    
                    if selected_layout:
                        result['selected_layout_file'] = selected_layout_path
                        input_for_refiner = selected_layout_path
                    else:
                        input_for_refiner = summary_json_path
                else:
                    # ç®€å•åœºæ™¯ï¼šç›´æ¥ä½¿ç”¨ summary
                    if verbose:
                        print("\nğŸ’¡ ç®€å•åœºæ™¯ï¼Œè·³è¿‡å¸ƒå±€é€‰æ‹©ï¼Œç›´æ¥ç”Ÿæˆç­”æ¡ˆ...")
                    input_for_refiner = summary_json_path
                
                # æ­¥éª¤ 8: ä½¿ç”¨ Phi3.5-Vision ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
                if verbose:
                    print("\nğŸ¤– æ­¥éª¤ 8: ä½¿ç”¨ Phi3.5-Vision ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ...")
                
                # ç”Ÿæˆæ–‡ä»¶å
                if sample_output_dir and output_path and output_path.startswith(sample_output_dir):
                    final_answer_path = str(Path(sample_output_dir) / "final_answer.json")
                elif output_path:
                    final_answer_path = output_path.replace('.json', '_final_answer.json')
                else:
                    # æ‰¹é‡å¤„ç†æ¨¡å¼ï¼šä½¿ç”¨ä¸´æ—¶è·¯å¾„ï¼ˆä¸å®é™…ä¿å­˜ï¼‰
                    import tempfile
                    final_answer_path = str(Path(tempfile.gettempdir()) / f"final_answer_{id(summary)}.json")
                
                final_answer = _generate_final_answer(
                    input_for_refiner,
                    final_answer_path,
                    verbose=verbose,
                    refiner=refiner
                )
                
                if final_answer:
                    result['final_answer'] = final_answer.get('refined_response', '')
                    result['final_answer_file'] = final_answer_path
                    if verbose:
                        print(f"\nğŸ’¡ æœ€ç»ˆç­”æ¡ˆ: {result['final_answer']}")
                    
            except Exception as e:
                print(f"\nâš ï¸  ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆå¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
    
    return result


def _integrate_layout_results(result: dict, image_path: str, verbose: bool = True) -> dict:
    """
    æ•´åˆå¸ƒå±€æ£€æµ‹ç»“æœ
    
    å¦‚æœæ‰§è¡Œç»“æœä¸­åŒ…å«å¸ƒå±€æ£€æµ‹ï¼ˆå¤šä¸ªåŒºåŸŸï¼‰ï¼Œä½¿ç”¨ merge_layout_blocks_ratio è¿›è¡Œï¼š
    1. åŒºåŸŸå»é‡ï¼ˆåˆ é™¤é‡å¤çš„æ£€æµ‹æ¡†ï¼‰
    2. æ–‡æœ¬è¡Œåˆå¹¶ï¼ˆå°†åŒä¸€æ®µè½çš„è¡Œåˆå¹¶ï¼‰
    3. å—çº§æ•´åˆï¼ˆåŸºäºæ ‡é¢˜ç­‰é”šç‚¹åˆå¹¶ç›¸å…³å†…å®¹ï¼‰
    4. è·¨å—å»é‡ï¼ˆåˆ é™¤è¢«å…¶ä»–å—åŒ…å«çš„å°å—ï¼‰
    
    Args:
        result: orchestrator çš„æ‰§è¡Œç»“æœ
        image_path: å›¾ç‰‡è·¯å¾„
        
    Returns:
        æ•´åˆåçš„ç»“æœ
    """
    exec_results = result.get('execution_results', {})
    layout_result = exec_results.get('layout_result', {})
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¸ƒå±€æ£€æµ‹ç»“æœ
    if not layout_result or layout_result.get('detected_regions', 0) == 0:
        return result
    
    if verbose:
        print("\nğŸ”„ æ£€æµ‹åˆ°å¸ƒå±€åŒºåŸŸï¼Œå¼€å§‹æ•´åˆ...")
    
    # æ„å»ºç¬¦åˆ merge_layout_blocks_ratio è¾“å…¥æ ¼å¼çš„æ•°æ®
    # éœ€è¦ä» layout_result å’Œ OCR ç»“æœä¸­æå–ä¿¡æ¯
    boxes = layout_result.get('boxes', [])
    
    # ä» agents_executed ä¸­æå– OCR ç»“æœ
    agents_executed = exec_results.get('agents_executed', [])
    ocr_agent_output = None
    for agent in agents_executed:
        if 'OCRAgent' in agent.get('agent_name', ''):
            ocr_agent_output = agent.get('output', '')
            break
    
    if not ocr_agent_output or not boxes:
        print("âš ï¸  æ²¡æœ‰è¶³å¤Ÿçš„ä¿¡æ¯è¿›è¡Œå¸ƒå±€æ•´åˆ")
        return result
    
    # è§£æ OCR è¾“å‡ºï¼Œæå–æ¯ä¸ªåŒºåŸŸçš„æ–‡å­—
    regions = _parse_ocr_output_to_regions(boxes, ocr_agent_output)
    
    if not regions:
        print("âš ï¸  æ— æ³•è§£æ OCR è¾“å‡º")
        return result
    
    # è·å–å›¾ç‰‡åˆ†è¾¨ç‡
    from PIL import Image
    try:
        img = Image.open(image_path)
        resolution = f"{img.width}x{img.height}"
    except:
        resolution = "unknown"
    
    # æ„å»ºè¾“å…¥æ–‡æ¡£
    doc = {
        "image_path": image_path,
        "resolution": resolution,
        "ocr_results": {
            "regions": regions
        }
    }
    
    # è°ƒç”¨å¸ƒå±€æ•´åˆå‡½æ•°
    try:
        merged_doc = merge_layout_regions_ratio_dedup_v2(doc)
        merged_blocks = merged_doc.get('ocr_results', {}).get('merged_blocks', [])
        
        if verbose:
            print(f"âœ“ å¸ƒå±€æ•´åˆå®Œæˆ:")
            print(f"  åŸå§‹åŒºåŸŸ: {len(regions)}")
            print(f"  æ•´åˆåå—æ•°: {len(merged_blocks)}")
        
        # æ›´æ–° result ä¸­çš„ layout_result
        if merged_blocks:
            layout_result['merged_blocks'] = merged_blocks
            layout_result['merge_stats'] = {
                'original_regions': len(regions),
                'merged_blocks': len(merged_blocks),
                'merge_params': merged_doc.get('ocr_results', {}).get('merge_params', {})
            }
        
    except Exception as e:
        print(f"âš ï¸  å¸ƒå±€æ•´åˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    return result


def _parse_ocr_output_to_regions(boxes: list, ocr_output: str) -> list:
    """
    ä» OCR Agent çš„è¾“å‡ºæ–‡æœ¬ä¸­è§£æå‡ºæ¯ä¸ªåŒºåŸŸçš„ä¿¡æ¯
    
    Args:
        boxes: å¸ƒå±€æ£€æµ‹çš„æ¡†åˆ—è¡¨
        ocr_output: OCR Agent çš„è¾“å‡ºæ–‡æœ¬
        
    Returns:
        regions åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« region_id, label, confidence, coordinate, text
    """
    regions = []
    
    # OCR è¾“å‡ºæ ¼å¼ï¼š
    # åŸºäºå¸ƒå±€æ£€æµ‹çš„ OCR ç»“æœï¼ˆå…± N ä¸ªåŒºåŸŸï¼‰ï¼š
    # 
    # åŒºåŸŸ 1: label (ç½®ä¿¡åº¦: X.XXX)
    # ä½ç½®: [x1, y1, x2, y2]
    # æ–‡å­—å†…å®¹:
    # ...
    # ------------------------------------------------------------
    # åŒºåŸŸ 2: ...
    
    # æŒ‰åˆ†éš”ç¬¦åˆ†å‰²
    region_blocks = ocr_output.split('------------------------------------------------------------')
    
    for i, box in enumerate(boxes):
        region_id = i + 1
        
        # æ‰¾åˆ°å¯¹åº”çš„æ–‡æœ¬å—
        block = None
        if i == 0 and region_blocks:
            # ç¬¬ä¸€ä¸ªåŒºåŸŸåœ¨ç¬¬ä¸€ä¸ªå—ä¸­ï¼ˆåŒ…å«æ ‡é¢˜ï¼‰
            block = region_blocks[0]
        elif i < len(region_blocks):
            block = region_blocks[i]
        
        if not block:
            # å¦‚æœæ²¡æœ‰å¯¹åº”çš„æ–‡æœ¬å—ï¼Œä½¿ç”¨ç©ºæ–‡æœ¬
            regions.append({
                "region_id": region_id,
                "label": box.get('label', 'unknown'),
                "confidence": box.get('score', 0.0),
                "coordinate": box.get('coordinate', []),
                "text": ""
            })
            continue
        
        # æå–æ–‡å­—å†…å®¹
        text = _extract_text_from_ocr_block(block)
        
        regions.append({
            "region_id": region_id,
            "label": box.get('label', 'unknown'),
            "confidence": box.get('score', 0.0),
            "coordinate": box.get('coordinate', []),
            "text": text
        })
    
    return regions


def _extract_text_from_ocr_block(block: str) -> str:
    """
    ä» OCR è¾“å‡ºå—ä¸­æå–æ–‡å­—å†…å®¹
    
    æŸ¥æ‰¾ "æ–‡å­—å†…å®¹:" æ ‡è®°ä¹‹åçš„æ‰€æœ‰æ–‡æœ¬
    """
    if not block:
        return ""
    
    # æŸ¥æ‰¾ "æ–‡å­—å†…å®¹:" æ ‡è®°
    marker = "æ–‡å­—å†…å®¹:"
    if marker not in block:
        marker = "æ–‡å­—å†…å®¹ï¼š"
    
    if marker not in block:
        return ""
    
    # æå–æ ‡è®°ä¹‹åçš„å†…å®¹
    parts = block.split(marker, 1)
    if len(parts) < 2:
        return ""
    
    text = parts[1].strip()
    
    # ç§»é™¤åé¢å¯èƒ½çš„åˆ†éš”çº¿
    if '----' in text:
        text = text.split('----')[0].strip()
    
    return text


def _select_relevant_layouts(summary: dict, image_path: str, output_path: str, 
                            auto_token_budget: bool = True, verbose: bool = True) -> dict:
    """
    æ ¹æ®ç”¨æˆ· query é€‰æ‹©ç›¸å…³çš„å¸ƒå±€åŒºåŸŸ
    
    Args:
        summary: pipeline ç”Ÿæˆçš„ summary JSON
        image_path: å›¾ç‰‡è·¯å¾„
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        auto_token_budget: æ˜¯å¦è‡ªåŠ¨è®¡ç®— token é¢„ç®—
        
    Returns:
        é€‰æ‹©åçš„å¸ƒå±€æ•°æ®
    """
    try:
        # å¯¼å…¥å¿…è¦çš„å‡½æ•°ï¼ˆä» layout_relevance_selector_v4.pyï¼‰
        from typing import List, Dict, Any
        
        def normalize_text(text: str) -> str:
            text = text.replace("-\n", "")
            text = re.sub(r"\s+", " ", text)
            return text.strip()
        
        def approx_token_len(text: str) -> int:
            return max(1, len(text) // 4)
        
        def cosine(a, b) -> float:
            dot = sum(x*y for x,y in zip(a,b))
            na = math.sqrt(sum(x*x for x in a))
            nb = math.sqrt(sum(x*x for x in b))
            return dot / (na*nb + 1e-9)
        
        def hash_embed(text: str, dim: int = 256):
            """ä½¿ç”¨ç¡®å®šæ€§å“ˆå¸Œ"""
            vec = [0.0]*dim
            for w in re.findall(r"\w+", text.lower()):
                hash_val = int(hashlib.md5(w.encode('utf-8')).hexdigest(), 16)
                vec[hash_val % dim] += 1.0
            return vec
        
        def select_blocks_by_relevance(regions, query, token_budget, per_block_max_tokens=200):
            q_emb = hash_embed(query)
            scored = []
            for r in regions:
                text = r.get("text") or ""
                normalized_text = normalize_text(text)
                
                emb = hash_embed(normalized_text[:800])
                score = cosine(q_emb, emb)
                scored.append({
                    "region_id": r.get("region_id"),
                    "score": score,
                    "text": normalized_text,
                    "bbox": r.get("coordinate"),
                    "label": r.get("label"),
                    "confidence": r.get("confidence")
                })
            scored.sort(key=lambda x: x["score"], reverse=True)
            
            selected, used = [], 0
            for s in scored:
                t = approx_token_len(s["text"])
                if t > per_block_max_tokens:
                    s["text"] = s["text"][:per_block_max_tokens*4]
                    t = per_block_max_tokens
                if used + t > token_budget:
                    break
                s["tokens"] = t
                selected.append(s)
                used += t
            return selected
        
        # è·å– query å’Œ regions
        query = summary.get("user_query", "")
        regions = summary.get("ocr_results", {}).get("regions", [])
        
        if not regions:
            print("âš ï¸  æ²¡æœ‰å¸ƒå±€åŒºåŸŸå¯ä¾›é€‰æ‹©")
            return None
        
        # è®¡ç®— token é¢„ç®—
        if auto_token_budget:
            calculator = TokenBudgetCalculator(num_crops=4)
            token_budget = calculator.get_text_budget(image_path, max_output_tokens=2000)
            if verbose:
                print(f"  âœ“ è‡ªåŠ¨è®¡ç®—çš„ token é¢„ç®—: {token_budget}")
        else:
            token_budget = 127000  # é»˜è®¤é¢„ç®—
        
        # é€‰æ‹©ç›¸å…³åŒºåŸŸ
        selected = select_blocks_by_relevance(regions, query, token_budget)
        
        # æ„å»ºè¾“å‡ºæ•°æ®
        result = {
            "image_path": summary.get("image_path"),
            "resolution": summary.get("resolution"),
            "user_query": query,
            "classification": summary.get("classification"),
            "agent_sequence": summary.get("agent_sequence"),
            "total_time": summary.get("total_time"),
            "mode": "query_relevance",
            "num_selected": len(selected),
            "blocks": selected
        }
        
        # ä¿å­˜ç»“æœ
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        if verbose:
            print(f"  âœ“ é€‰æ‹©äº† {len(selected)} ä¸ªç›¸å…³åŒºåŸŸ")
            print(f"  âœ“ ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        
        return result
        
    except Exception as e:
        print(f"  âš ï¸ å¸ƒå±€é€‰æ‹©å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def _generate_final_answer(selected_layout_path: str, output_path: str, verbose: bool = True, 
                          refiner: 'PhiRefiner' = None) -> dict:
    """
    ä½¿ç”¨ Phi3.5-Vision ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
    
    Args:
        selected_layout_path: é€‰æ‹©åçš„å¸ƒå±€ JSON æ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
        refiner: å¤ç”¨çš„ refiner å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        åŒ…å«æœ€ç»ˆç­”æ¡ˆçš„å­—å…¸
    """
    try:
        # åˆ›å»ºæˆ–å¤ç”¨ PhiRefiner
        if refiner is None:
            from phi_refiner import PhiRefiner
            refiner = PhiRefiner()
        
        # ä» selected_layout JSON ç”Ÿæˆç­”æ¡ˆ
        result = refiner.refine_from_summary_file(selected_layout_path)
        
        if "error" in result:
            print(f"  âš ï¸ ç”Ÿæˆç­”æ¡ˆå¤±è´¥: {result['error']}")
            return None
        
        # ä¿å­˜ç»“æœ
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        if verbose:
            print(f"  âœ“ ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        
        return result
        
    except Exception as e:
        print(f"  âš ï¸ ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def print_summary(results: list):
    """æ‰“å°å¤„ç†ç»“æœæ‘˜è¦"""
    print("\n\n" + "="*70)
    print(" " * 25 + "å¤„ç†ç»“æœæ‘˜è¦")
    print("="*70)
    
    for i, result in enumerate(results, 1):
        if result is None:
            continue
        
        # è·å–åˆ†ç±»ç»“æœ
        classification = result.get('classification', {})
        label = classification.get('label', 'unknown')
        confidence = classification.get('confidence', 0.0)
        
        # è·å–æ‰§è¡Œç»“æœ
        exec_results = result.get("execution_results", {})
        final_output = exec_results.get("final_output", "æ— ")
        layout_result = exec_results.get("layout_result", {})
        
        # è·å–ä½¿ç”¨çš„ Agent
        agents_executed = exec_results.get("agents_executed", [])
        agent_names = [a.get("agent_name", "") for a in agents_executed]
        agent_sequence = " â†’ ".join(agent_names) if agent_names else "None"
        
        print(f"\nã€ä»»åŠ¡ {i}ã€‘")
        print("-" * 70)
        print(f"å›¾ç‰‡: {result['image_path']}")
        print(f"åˆ†ç±»: {label} (ç½®ä¿¡åº¦: {confidence:.3f})")
        print(f"Agent æ‰§è¡Œåºåˆ—: {agent_sequence}")
        
        # å¦‚æœæœ‰å¸ƒå±€æ£€æµ‹ç»“æœï¼Œæ˜¾ç¤ºåŒºåŸŸæ•°é‡
        if layout_result and layout_result.get('detected_regions', 0) > 0:
            print(f"å¸ƒå±€æ£€æµ‹: {layout_result['detected_regions']} ä¸ªåŒºåŸŸ")
        
        print(f"è§„åˆ’æ—¶é—´: {result.get('planning_time', 0):.2f}ç§’")
        print(f"æ‰§è¡Œæ—¶é—´: {result.get('execution_time', 0):.2f}ç§’")
        print(f"æ€»æ—¶é—´: {result.get('total_time', 0):.2f}ç§’")
        
        # æ˜¾ç¤ºæ‘˜è¦æ–‡ä»¶ä½ç½®
        if 'summary_files' in result:
            print(f"\næ‘˜è¦æ–‡ä»¶:")
            print(f"  ğŸ“Š JSON: {result['summary_files']['summary_json']}")
            print(f"  ğŸ“ æç¤º: {result['summary_files']['prompt_txt']}")
        
        print(f"\nOCR ç»“æœé¢„è§ˆ:")
        preview_text = final_output[:200] + "..." if len(final_output) > 200 else final_output
        print(preview_text)
    
    print("\n" + "="*70)


def process_from_json(json_path: str, output_file: str = "predictions.json", 
                     limit: int = None, enable_refinement: bool = True):
    """
    ä» JSON æ–‡ä»¶æ‰¹é‡å¤„ç†æµ‹è¯•æ•°æ®ï¼Œè¾“å‡ºå•ä¸ªæ±‡æ€» JSON æ–‡ä»¶
    
    Args:
        json_path: JSON æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚ OCRBench.jsonï¼‰
        output_file: è¾“å‡º JSON æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: predictions.jsonï¼‰
        limit: é™åˆ¶å¤„ç†çš„æ•°é‡ï¼ŒNone è¡¨ç¤ºå¤„ç†å…¨éƒ¨
        enable_refinement: æ˜¯å¦å¯ç”¨æœ€ç»ˆç­”æ¡ˆç”Ÿæˆ
        
    Returns:
        å¤„ç†ç»“æœåˆ—è¡¨
    """
    from pathlib import Path
    try:
        from tqdm import tqdm
    except ImportError:
        print("âš ï¸  æœªå®‰è£… tqdmï¼Œä½¿ç”¨ç®€å•è¿›åº¦æ˜¾ç¤ºã€‚å®‰è£…: pip install tqdm")
        tqdm = None
    
    # è¯»å– JSON æ–‡ä»¶
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_path = Path(output_file)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    results = []
    total = len(data) if limit is None else min(limit, len(data))
    
    print(f"\nğŸ“‹ ä» {json_path} è¯»å–åˆ° {len(data)} ä¸ªæµ‹è¯•æ ·æœ¬")
    if limit:
        print(f"   é™åˆ¶å¤„ç†å‰ {limit} ä¸ªæ ·æœ¬")
    print("=" * 70)
    
    # åœ¨æ‰¹å¤„ç†å¼€å§‹å‰åˆ›å»ºå…±äº«çš„æ¨¡å‹å®ä¾‹ï¼ˆé¿å…é‡å¤åŠ è½½ï¼‰
    print("\nâš¡ åˆå§‹åŒ–æ¨¡å‹ï¼ˆæ‰¹å¤„ç†æ¨¡å¼ï¼Œæ¨¡å‹å¤ç”¨ + RuntimeContextï¼‰...")
    shared_orchestrator = MultiAgentOrchestrator(execute_agents=True)
    
    # åˆ›å»ºå…±äº«çš„ refinerï¼ˆå¦‚æœéœ€è¦ï¼‰ï¼Œæ³¨å…¥ orchestrator çš„ ctx
    shared_refiner = None
    if enable_refinement:
        from phi_refiner import PhiRefiner
        shared_refiner = PhiRefiner(ctx=shared_orchestrator.ctx)
        print("âœ“ æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
    
    # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦æ¡
    if tqdm:
        pbar = tqdm(data[:total], desc="å¤„ç†è¿›åº¦", unit="æ ·æœ¬", 
                   bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]')
    else:
        pbar = data[:total]
    
    success_count = 0
    fail_count = 0
    skip_count = 0
    
    for i, item in enumerate(pbar, 1):
        image_path = item.get('image_path', '')
        query = item.get('question', item.get('query', ''))
        
        if not image_path or not query:
            # è·³è¿‡ä½†ä¿ç•™åŸå§‹æ•°æ®ï¼Œpredict è®¾ä¸ºç©º
            item_copy = item.copy()
            item_copy['predict'] = ""
            results.append(item_copy)
            skip_count += 1
            if tqdm:
                pbar.set_postfix({'æˆåŠŸ': success_count, 'å¤±è´¥': fail_count, 'è·³è¿‡': skip_count})
            else:
                print(f"\n[{i}/{total}] âš ï¸  è·³è¿‡ï¼šç¼ºå°‘ image_path æˆ– question")
            continue
        
        # ä¿®æ­£å›¾ç‰‡è·¯å¾„ï¼šå¦‚æœè·¯å¾„ä¸ä»¥ OCRBench_Images/ å¼€å¤´ï¼Œä¸”æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•æ·»åŠ å‰ç¼€
        original_image_path = image_path
        if not Path(image_path).exists():
            # å°è¯•æ·»åŠ  OCRBench_Images/ å‰ç¼€
            prefixed_path = f"OCRBench_Images/{image_path}" if not image_path.startswith("OCRBench_Images/") else image_path
            if Path(prefixed_path).exists():
                image_path = prefixed_path
        
        if not tqdm:
            print(f"\n[{i}/{total}] å¤„ç†: {Path(image_path).name}")
        
        try:
            result = process_image(
                image_path=image_path,
                query=query,
                output_path=None,  # ä¸ä¿å­˜ä¸­é—´æ–‡ä»¶
                example_name=None,  # æ‰¹é‡å¤„ç†æ—¶ä¸æ˜¾ç¤ºè¯¦ç»†ä»»åŠ¡ä¿¡æ¯
                generate_summary=True,
                enable_refinement=enable_refinement,
                verbose=False,  # æ‰¹é‡å¤„ç†æ—¶é™é»˜æ¨¡å¼
                sample_output_dir=None,  # ä¸éœ€è¦æ ·æœ¬ç›®å½•
                orchestrator=shared_orchestrator,  # å¤ç”¨æ¨¡å‹
                refiner=shared_refiner  # å¤ç”¨æ¨¡å‹
            )
            
            # æ„å»ºè¾“å‡ºé¡¹ï¼šåŸå§‹ item + predict å­—æ®µ
            item_copy = item.copy()
            if result and 'final_answer' in result:
                item_copy['predict'] = result['final_answer']
                success_count += 1
                if tqdm:
                    answer_preview = result['final_answer'][:20] + "..." if len(result['final_answer']) > 20 else result['final_answer']
                    pbar.set_postfix({
                        'æˆåŠŸ': success_count, 
                        'å¤±è´¥': fail_count, 
                        'è·³è¿‡': skip_count
                    })
                else:
                    print(f"   âœ“ ç­”æ¡ˆ: {result['final_answer']}")
            else:
                # å¤„ç†å¤±è´¥ï¼šresultä¸ºç©ºæˆ–æ²¡æœ‰final_answer
                print(f"\n   âš ï¸  å¤„ç†å¤±è´¥ (å›¾ç‰‡: {image_path})")
                print(f"      è¿”å›ç»“æœ: {result}")
                item_copy['predict'] = ""
                fail_count += 1
                if tqdm:
                    pbar.set_postfix({'æˆåŠŸ': success_count, 'å¤±è´¥': fail_count, 'è·³è¿‡': skip_count})
            
            results.append(item_copy)
                    
        except Exception as e:
            # å¤±è´¥æ—¶ä¹Ÿä¿ç•™åŸå§‹æ•°æ®ï¼Œpredict è®¾ä¸ºç©º
            print(f"\n   âŒ å¤„ç†å¤±è´¥ (å›¾ç‰‡: {image_path}): {e}")
            import traceback
            traceback.print_exc()
            
            item_copy = item.copy()
            item_copy['predict'] = ""
            results.append(item_copy)
            fail_count += 1
            if tqdm:
                pbar.set_postfix({'æˆåŠŸ': success_count, 'å¤±è´¥': fail_count, 'è·³è¿‡': skip_count})
            continue
    
    if tqdm:
        pbar.close()
    
    # ä¿å­˜æ±‡æ€»ç»“æœåˆ°å•ä¸ª JSON æ–‡ä»¶
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=4)
    
    print(f"\n{'='*70}")
    print(f"ğŸ“Š å¤„ç†å®Œæˆç»Ÿè®¡:")
    print(f"   âœ“ æˆåŠŸ: {success_count}")
    print(f"   âœ— å¤±è´¥: {fail_count}")
    print(f"   âš ï¸  è·³è¿‡: {skip_count}")
    print(f"   ğŸ“ æ€»è®¡: {success_count + fail_count + skip_count}/{total}")
    print(f"   ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    print(f"{'='*70}\n")
    
    return results


def main():
    """ä¸»å‡½æ•° - æ”¯æŒå‘½ä»¤è¡Œå‚æ•°å’Œé»˜è®¤ç¤ºä¾‹"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Multi-Agent OCR Pipeline - æ™ºèƒ½ OCR å¤„ç†æµç¨‹",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # è¿è¡Œé»˜è®¤ç¤ºä¾‹
  python case2/pipeline.py
  
  # ä» OCRBench.json æ‰¹é‡å¤„ç†ï¼ˆå¤„ç†å‰10ä¸ªï¼‰
  python case2/pipeline.py --json OCRBench.json --limit 10 --output result.json
  
  # å¤„ç†å•ä¸ªå›¾ç‰‡
  python case2/pipeline.py --image path/to/image.jpg --query "è¯†åˆ«æ–‡å­—"
  
  # ç¦ç”¨æœ€ç»ˆç­”æ¡ˆç”Ÿæˆï¼ˆåªåš OCRï¼‰
  python case2/pipeline.py --json OCRBench.json --no-refine --output result.json
        """
    )
    
    parser.add_argument('--json', type=str, help='ä» JSON æ–‡ä»¶æ‰¹é‡å¤„ç†ï¼ˆå¦‚ OCRBench.jsonï¼‰')
    parser.add_argument('--limit', type=int, help='é™åˆ¶å¤„ç†æ•°é‡')
    parser.add_argument('--image', type=str, help='å•ä¸ªå›¾ç‰‡è·¯å¾„')
    parser.add_argument('--query', type=str, help='æŸ¥è¯¢é—®é¢˜ï¼ˆä¸ --image é…åˆä½¿ç”¨ï¼‰')
    parser.add_argument('--output', type=str, default='predictions.json', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: predictions.jsonï¼‰')
    parser.add_argument('--no-refine', action='store_true', help='ç¦ç”¨æœ€ç»ˆç­”æ¡ˆç”Ÿæˆ')
    
    args = parser.parse_args()
    
    print("\n" + "="*70)
    print(" " * 15 + "Multi-Agent OCR Pipeline")
    print(" " * 10 + "è‡ªåŠ¨åˆ¤æ–­å›¾ç‰‡ç±»å‹å¹¶è°ƒç”¨å¯¹åº”çš„ Agent")
    print("="*70)
    print("\nå·¥ä½œæµç¨‹ï¼š")
    print("  1. Target Detection - è‡ªåŠ¨åˆ¤æ–­å›¾ç‰‡ç±»å‹ï¼ˆæ‰‹å†™ä½“/å°åˆ·ä½“ï¼‰")
    print("  2. Phi3.5-Vision - åˆ†æå›¾ç‰‡è´¨é‡å’Œå¤æ‚åº¦")
    print("  3. Prompt Generator - ç”Ÿæˆç»“æ„åŒ–æ‰§è¡Œè®¡åˆ’")
    print("  4. Agent Execution - è‡ªåŠ¨é€‰æ‹©å¹¶æ‰§è¡Œå¯¹åº”çš„ Agent")
    if not args.no_refine:
        print("  5. Layout Selection - é€‰æ‹©ç›¸å…³å¸ƒå±€åŒºåŸŸï¼ˆå¤æ‚åœºæ™¯ï¼‰")
        print("  6. Answer Refinement - Phi3.5-Vision ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ")
    print("="*70)
    
    results = []
    
    # æ¨¡å¼ 1: ä» JSON æ–‡ä»¶æ‰¹é‡å¤„ç†
    if args.json:
        results = process_from_json(
            json_path=args.json,
            output_file=args.output,
            limit=args.limit,
            enable_refinement=not args.no_refine
        )
    
    # æ¨¡å¼ 2: å¤„ç†å•ä¸ªå›¾ç‰‡
    elif args.image:
        if not args.query:
            print("âŒ é”™è¯¯: ä½¿ç”¨ --image æ—¶å¿…é¡»æŒ‡å®š --query")
            return
        
        from pathlib import Path
        image_name = Path(args.image).stem
        output_path = str(Path(args.output) / f"{image_name}_result.json")
        
        result = process_image(
            image_path=args.image,
            query=args.query,
            output_path=output_path,
            example_name=f"è‡ªå®šä¹‰: {image_name}",
            enable_refinement=not args.no_refine
        )
        if result:
            results.append(result)
    
    # æ¨¡å¼ 3: è¿è¡Œé»˜è®¤ç¤ºä¾‹
    else:
        print("\nğŸ’¡ è¿è¡Œé»˜è®¤ç¤ºä¾‹ï¼ˆä½¿ç”¨ --help æŸ¥çœ‹æ›´å¤šé€‰é¡¹ï¼‰\n")
    
    # ç¤ºä¾‹ 1: å¤æ‚å°åˆ·ä½“æ–‡æ¡£
    # result1 = process_image(
    #     image_path="OCRBench_Images/docVQA/val/documents/flpp0227_16.png",
    #         query="Which company has vacancies to the post of general manager and operating engineer?",
    #     output_path="case2_output/example1_result.json",
    #         example_name="ç¤ºä¾‹ 1 - å¤æ‚æ–‡æ¡£",
    #         enable_refinement=not args.no_refine
    # )
    # if result1:
    #     results.append(result1)
    
    
    # æ‰“å°æ‘˜è¦ï¼ˆå¯¹äºå•ä¸ªå›¾ç‰‡å¤„ç†ï¼‰
    if results and args.image:
        print_summary(results)
    
    if args.json:
        print("\nâœ“ Pipeline æ‰§è¡Œå®Œæˆï¼")
        print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {args.output}")
    elif args.image:
        print("\nâœ“ Pipeline æ‰§è¡Œå®Œæˆï¼")
        print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {args.output}")
    print()


if __name__ == "__main__":
    main()

